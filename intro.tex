\section{Introduction}
\label{sec:intro}

With the increasing of sensor performance and the rapid expansion of social network data, it is necessary to parallelize or distribute the analysis and computation of large scale data. However, the parallelization of algorithms requires programmers to have a rich knowledge of distributed systems. A large number of big data analysis systems have been proposed which provide high-level language for expressing the computation logic \cite{}. Even so, these systems still require the users to understand the specific programming logic. For example, the typical representative of the BSP computing model, Pregel \cite{} adopts a vertex-centric programming model. It requires programmers to write vertex-centric programs and to manage the communication based on the algorithm. 

%Maiter[$]is an asynchronous graph computing system which proposed a delta-based accumulative iterative computation method. Maiter provide an asynchronous programming model, demand the programmer rewrite the algorithm in a DAIC way. The complexity of parallize or distribute an algorithm wasn’t significantly reduced.


%Its core advantage to  relational query languages is its elegant notation for expressing recursion.but it is not widely adopted as practical query language because of the lack of negation. In particular, it cannot express even the first-order queries which limited the usage.While since 2010 datalog is getting  more popular due to the graph/social network processing requirement. 

New interest has recently re-emerged around Datalog for a wide spectrum of knowledge-oriented applications \cite{Bigdatalog 25,27,64,47,49}.
%[25], AI [27], and distributed data management [64], as well as analytics on single-node systems [47, 49]. The fact that Datalog is also well suited to declaratively support large-scale analytics was recently recognized by [48, 54].
Datalog is an excellent candidate language for large-scale data analytics because of its high-level declarative semantics and support for recursion. Datalog's support for recursion makes the expression of data analysis natural \cite{} and its high-level semantics makes it amenable to parallelization and optimization \cite{}. 
%Although many advantages it has，the performance of Datalog is not competitive when compared with other languages.
In recent years, many system research efforts have raised to improve the performance and scalability of Datalog systems. Socialite \cite{socialite} provides a large scale graph evaluation system supporting both sequential and distribute environment. In Socialite, users can define recursive aggregate functions which, as long as they are meet operations, can be evaluated incrementally and efficiently. The \textit{DeALS} project provides a full Datalog language implementation and seeks to provide  system supports that optimizes execution over diverse platforms including sequential implementations \cite{bigdatalog 49}, multi-core machines [59], and clusters \cite{bigdatalog}. It supports relational algebra, aggregation, and recursion, as well as a host of declarative optimizations. MyriaX \cite{} implements a Datalog System on share-nothing engines based on Myria \cite{}. The computations are incremental, and it support s a variety of iterative models (synchronous, asynchronous, different processing priorities) and failure-handling techniques. It is worth mentioning that MyriaX supports asynchronous processing and shows promising performance for some applications, but it fails to tell in which cases asynchronous processing is suited.

%It is worth mentioning that MyriaX is the first work that proposed recursive program with aggregation.And  inspired by this work.We present arbitary recurive parallel algorithm with two type of operations  aggregattion and non-aggregation in our approach which makes it more convenient to analyze and parallize.We will discuss in detail later in this paper. 
%[$Myria],a big data management system.[放这段最后，重点强调异步] It is worth mentioning that MyriaX is the first work thatUsually support recursive program with aggregation.


Compared with synchronous recursive processing, asynchronous recursive processing has many advantages, such as fast convergence \cite{}, more efficient resource utilization \cite{}, and priority scheduling \cite{}. However, in practical usage, synchronous systems are more popular than asynchronous systems, which can be attributed to the following three points:

First, \textbf{Non-guaranteed Correctness}. There are several prior works that have employed asynchronous processing engine for improving their system performance. However, these systems only implement asynchronous execution of parallel/distributed algorithms, without any correctness guarantee of the results \cite{groute, graphlab,...}. Asynchronous computation model are blindly used and may result in inconsistent results for convex functions. Maiter \cite{} provides the sufficient conditions for correct asynchronous computations, but these conditions are only suitable in the context of vertex-centric graph computations. 

Second, \textbf{More Complexity}. Programmers are used to write sequential programs or synchronous parallel programs. Had the asynchronization conditions been formally given, it is still hard for a non-expert programmer to manually verify these conditions from their programs. In addition, writing asynchronous programs and designing asynchronous systems are even harder, because asynchronous implies disorganized and as a result complicated. Experience from Google \cite{} strongly suggests a synchronous programming model, since asynchronous code is a lot harder to write, tune, and debug. 

Third, \textbf{Unstable Performance}. Asynchronous iterative processing avoids the intermediate result coordination phase. The parallel executions of operations are not synchronized and not strictly ordered. This implies that the computations and communications are not under control any more, which may lead to stale computations/communications and potentially reduces the efficiency. The performance gain from asynchronous computation may be not enough to compensate for the performance loss from stale computations/commmunications, leading to unstable performance.


In order to solve these problems, we design and implement a Datalog system supporting automated asynchronous execution, A3Log. Our system is able to automatically check whether a recursive Datalog program can return correct result with asynchronous recursive execution. This is achieved by automated sufficient conditions verification. Maiter \cite{} provides the sufficient conditions for asynchronous graph processing. In this paper, we generalize the sufficient conditions through the analysis of aggregate and non-aggregate operators, which can be easily identified from a user's Datalog program. Aggregate operation is known to be hardly parallelized \cite{distribute aggregate from ms}, while non-aggregate operation can be embarrassingly parallel. Synchronization of parallel computations seems to be the unavoidable coordination step for correct aggregation result though it is known costly. Our new sufficient conditions are provided by analyzing the properties of aggregate operations and non-aggregate operations. A3Log can also automate the condition verification process without user's participation. Further, A3Log provides both shared-memory runtime engine and distributed runtime engine for fast execution. 


%For example, MapReduce \cite{} decomposes a computation into (non-aggregate) map operations and (aggregate) reduce operations so as to parallelize the non-aggregate map operations and parallelize the reduce operations separately. But the synchronization barrier before reduce phase is indispensable due to the aggregation property. Given the aggregate operation and non-aggregate operation learned from user's Datalog program, A3Log is able to

%correctly asynchronized according to a novel Sufficient Condition by datalog program.Note that,different from the previous work Maiter[] which proposed asynchronous condition of graph algorithm .Our approach is based on aggregation operation and more generalized to apply on more algorithm except graph analysis .Such that Asynchronous calculations needn’t to be used blindly. And the workload of the programmer is greatly reduced. In order to meet different use requirements, system provides both  shared-memory runtime engine and distributed runtime engine. The contribution are summarized as follow

The contributions of this paper are summarized as follows.
\begin{itemize}
\item To guarantee the correctness of recursive Datalog program, we clearly define the sufficient conditions that guarantee asynchronous processing to return the same result as synchronous processing through the analysis of aggregate and non-aggregate operators. Even for some recursive programs that do not satisfy these conditions, we propose an approach to conditionally convert them to be qualified for asynchronous aggregation. 
\item To alleviate the burden of programmers, we propose an automated condition verification technique by leveraging satisfiability modulo theories
(SMT) . User?s sequential program can be automatically checked for asynchronization possibilities and can even be automatically converted to the asynchronous program.
\item We propose a Datalog implementation, A3Log, to support automated asynchronous aggregation. A3Log is built by modifying distributed Socialite \cite{}. The condition verification techniques are embedded in a Condition Checker component, so that it can asynchronize user?s program automatically. A3Log provides both shared-memory runtime engine and distributed runtime engine. The evaluation of a Datalog program are mapped to the update of a distributed hash table structure. By various optimizations, such as concurrency control, priority scheduling, and termination control, users' Datalog programs can be efficiently executed on our system.
\item We experimentally evaluate A3Log, compared with Socialite [30, 39], GraphLab [33], Myria[49] and Maiter [55].We also perform evaluations with 7 algorithms on 20 more datasets. The experiments are performed on a 32-core instance for many-core experiments and on a cluster with 64 instances for distributed experiments. Our results show that A3Log outperforms other systems in many-core experiments and shows comparable performance with Maiter in distributed experiments. Our results also show that the asynchronous execution of A3Log can achieve 2.25X-222.82X speedup over the synchronous version for various datasets.
\end{itemize}

The rest of the paper are organized as follow: In Sec.2 we describe the details of  automatic asynchronous technology. In Sec.3 we propose a datalog system based on automatic asynchronous the technology .In Section.4  we give the performance evaluation. And then we review the related works in Sec 5 and then conclude the paper in Sec.7
	
	
	
	
	